{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded en_core_web_sm model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 1:   0%|          | 0/10 [00:00<?, ?it/s]2024-07-23 00:17:11,078 - INFO - Processed and saved: preprocessed_data/cells-12-02579-compressed_cleaned.txt\n",
      "Processing batch 1:  10%|█         | 1/10 [00:00<00:04,  2.01it/s]2024-07-23 00:17:11,328 - INFO - Processed and saved: preprocessed_data/ijms-22-07207_cleaned.txt\n",
      "Processing batch 1:  20%|██        | 2/10 [00:00<00:02,  2.84it/s]2024-07-23 00:17:11,735 - INFO - Processed and saved: preprocessed_data/biomolecules-12-00455-compressed_cleaned.txt\n",
      "Processing batch 1:  30%|███       | 3/10 [00:01<00:02,  2.65it/s]2024-07-23 00:17:11,982 - INFO - Processed and saved: preprocessed_data/EMMM-14-e15941-compressed_cleaned.txt\n",
      "Processing batch 1:  40%|████      | 4/10 [00:01<00:01,  3.07it/s]2024-07-23 00:17:12,414 - INFO - Processed and saved: preprocessed_data/jcm-12-06953_cleaned.txt\n",
      "Processing batch 1:  50%|█████     | 5/10 [00:01<00:01,  2.75it/s]2024-07-23 00:17:12,626 - INFO - Processed and saved: preprocessed_data/41436_2020_Article_759_cleaned.txt\n",
      "Processing batch 1:  60%|██████    | 6/10 [00:02<00:01,  3.20it/s]2024-07-23 00:17:13,001 - INFO - Processed and saved: preprocessed_data/13023_2021_Article_2145_cleaned.txt\n",
      "Processing batch 1:  70%|███████   | 7/10 [00:02<00:00,  3.00it/s]2024-07-23 00:17:13,338 - INFO - Processed and saved: preprocessed_data/genes-14-00074_cleaned.txt\n",
      "Processing batch 1:  80%|████████  | 8/10 [00:02<00:00,  2.94it/s]2024-07-23 00:17:13,511 - INFO - Processed and saved: preprocessed_data/JCO-34-80_cleaned.txt\n",
      "Processing batch 1:  90%|█████████ | 9/10 [00:02<00:00,  3.55it/s]2024-07-23 00:17:14,513 - INFO - Processed and saved: preprocessed_data/biomolecules-13-00271_cleaned.txt\n",
      "Processing batch 1: 100%|██████████| 10/10 [00:03<00:00,  2.54it/s]\n",
      "Processing batch 2:   0%|          | 0/10 [00:00<?, ?it/s]2024-07-23 00:17:14,700 - INFO - Processed and saved: preprocessed_data/fgene-13-858556_cleaned.txt\n",
      "Processing batch 2:  10%|█         | 1/10 [00:00<00:01,  5.46it/s]2024-07-23 00:17:15,335 - INFO - Processed and saved: preprocessed_data/ijms-22-04534_cleaned.txt\n",
      "Processing batch 2:  20%|██        | 2/10 [00:00<00:03,  2.22it/s]2024-07-23 00:17:15,505 - INFO - Processed and saved: preprocessed_data/diagnostics-13-00850_cleaned.txt\n",
      "Processing batch 2:  30%|███       | 3/10 [00:00<00:02,  3.11it/s]2024-07-23 00:17:15,700 - INFO - Processed and saved: preprocessed_data/nihms-1927912_cleaned.txt\n",
      "Processing batch 2:  40%|████      | 4/10 [00:01<00:01,  3.68it/s]2024-07-23 00:17:15,829 - INFO - Processed and saved: preprocessed_data/opth-16-1127_cleaned.txt\n",
      "Processing batch 2:  50%|█████     | 5/10 [00:01<00:01,  4.54it/s]2024-07-23 00:17:15,876 - INFO - Processed and saved: preprocessed_data/nihms-1747988_cleaned.txt\n",
      "2024-07-23 00:17:16,274 - INFO - Processed and saved: preprocessed_data/13023_2023_Article_2798_cleaned.txt\n",
      "Processing batch 2:  70%|███████   | 7/10 [00:01<00:00,  4.52it/s]2024-07-23 00:17:16,603 - INFO - Processed and saved: preprocessed_data/emss-80329_cleaned.txt\n",
      "Processing batch 2:  80%|████████  | 8/10 [00:02<00:00,  4.00it/s]2024-07-23 00:17:16,845 - INFO - Processed and saved: preprocessed_data/41598_2021_Article_81093_cleaned.txt\n",
      "Processing batch 2:  90%|█████████ | 9/10 [00:02<00:00,  4.03it/s]2024-07-23 00:17:17,012 - INFO - Processed and saved: preprocessed_data/TJO-53-44_cleaned.txt\n",
      "Processing batch 2: 100%|██████████| 10/10 [00:02<00:00,  4.01it/s]\n",
      "Processing batch 3:   0%|          | 0/10 [00:00<?, ?it/s]2024-07-23 00:17:17,256 - INFO - Processed and saved: preprocessed_data/nihms-1914935_cleaned.txt\n",
      "Processing batch 3:  10%|█         | 1/10 [00:00<00:02,  4.15it/s]2024-07-23 00:17:17,439 - INFO - Processed and saved: preprocessed_data/NRR-18-701_cleaned.txt\n",
      "Processing batch 3:  20%|██        | 2/10 [00:00<00:01,  4.83it/s]2024-07-23 00:17:17,588 - INFO - Processed and saved: preprocessed_data/12886_2023_Article_2772-compressed_cleaned.txt\n",
      "Processing batch 3:  30%|███       | 3/10 [00:00<00:01,  5.54it/s]2024-07-23 00:17:18,129 - INFO - Processed and saved: preprocessed_data/1-s2.0-S1350946221000367-main_cleaned.txt\n",
      "Processing batch 3:  40%|████      | 4/10 [00:01<00:01,  3.10it/s]2024-07-23 00:17:18,419 - INFO - Processed and saved: preprocessed_data/nihpp-rs3011096v1-compressed_cleaned.txt\n",
      "Processing batch 3:  50%|█████     | 5/10 [00:01<00:01,  3.21it/s]2024-07-23 00:17:18,636 - INFO - Processed and saved: preprocessed_data/IJO-70-2316_cleaned.txt\n",
      "Processing batch 3:  60%|██████    | 6/10 [00:01<00:01,  3.58it/s]2024-07-23 00:17:19,025 - INFO - Processed and saved: preprocessed_data/nihms-1685213_cleaned.txt\n",
      "Processing batch 3:  70%|███████   | 7/10 [00:02<00:00,  3.17it/s]2024-07-23 00:17:19,442 - INFO - Processed and saved: preprocessed_data/diagnostics-13-02413-compressed_cleaned.txt\n",
      "Processing batch 3:  80%|████████  | 8/10 [00:02<00:00,  2.88it/s]2024-07-23 00:17:19,712 - INFO - Processed and saved: preprocessed_data/main_cleaned.txt\n",
      "Processing batch 3:  90%|█████████ | 9/10 [00:02<00:00,  3.09it/s]2024-07-23 00:17:19,845 - INFO - Processed and saved: preprocessed_data/nihms-1933615_cleaned.txt\n",
      "Processing batch 3: 100%|██████████| 10/10 [00:02<00:00,  3.53it/s]\n",
      "Processing batch 4:   0%|          | 0/10 [00:00<?, ?it/s]2024-07-23 00:17:20,104 - INFO - Processed and saved: preprocessed_data/main (1)_cleaned.txt\n",
      "Processing batch 4:  10%|█         | 1/10 [00:00<00:02,  4.03it/s]2024-07-23 00:17:20,596 - INFO - Processed and saved: preprocessed_data/PIIS0039625723001030_cleaned.txt\n",
      "Processing batch 4:  20%|██        | 2/10 [00:00<00:03,  2.55it/s]2024-07-23 00:17:20,848 - INFO - Processed and saved: preprocessed_data/TJP-600-4623_cleaned.txt\n",
      "Processing batch 4:  30%|███       | 3/10 [00:00<00:02,  3.05it/s]2024-07-23 00:17:21,290 - INFO - Processed and saved: preprocessed_data/jci-133-171356_cleaned.txt\n",
      "Processing batch 4:  40%|████      | 4/10 [00:01<00:02,  2.68it/s]2024-07-23 00:17:21,870 - INFO - Processed and saved: preprocessed_data/ijms-22-05684_cleaned.txt\n",
      "Processing batch 4:  50%|█████     | 5/10 [00:02<00:02,  2.23it/s]2024-07-23 00:17:21,982 - INFO - Processed and saved: preprocessed_data/41433_2022_Article_2262_cleaned.txt\n",
      "Processing batch 4:  60%|██████    | 6/10 [00:02<00:01,  3.00it/s]2024-07-23 00:17:22,170 - INFO - Processed and saved: preprocessed_data/41525_2021_Article_180_cleaned.txt\n",
      "Processing batch 4:  70%|███████   | 7/10 [00:02<00:00,  3.50it/s]2024-07-23 00:17:22,480 - INFO - Processed and saved: preprocessed_data/genes-12-00147_cleaned.txt\n",
      "Processing batch 4:  80%|████████  | 8/10 [00:02<00:00,  3.41it/s]2024-07-23 00:17:22,845 - INFO - Processed and saved: preprocessed_data/nihms880229_cleaned.txt\n",
      "Processing batch 4:  90%|█████████ | 9/10 [00:02<00:00,  3.17it/s]2024-07-23 00:17:23,181 - INFO - Processed and saved: preprocessed_data/13287_2023_Article_3526_cleaned.txt\n",
      "Processing batch 4: 100%|██████████| 10/10 [00:03<00:00,  3.01it/s]\n",
      "Processing batch 5:   0%|          | 0/10 [00:00<?, ?it/s]2024-07-23 00:17:23,409 - INFO - Processed and saved: preprocessed_data/nihms-1567493_cleaned.txt\n",
      "Processing batch 5:  10%|█         | 1/10 [00:00<00:02,  4.49it/s]2024-07-23 00:17:23,624 - INFO - Processed and saved: preprocessed_data/iovs-63-2-11_cleaned.txt\n",
      "Processing batch 5:  20%|██        | 2/10 [00:00<00:01,  4.59it/s]2024-07-23 00:17:23,816 - INFO - Processed and saved: preprocessed_data/MGG3-9-e1663_cleaned.txt\n",
      "Processing batch 5:  30%|███       | 3/10 [00:00<00:01,  4.85it/s]2024-07-23 00:17:24,316 - INFO - Processed and saved: preprocessed_data/10.1177_2515841420954592_cleaned.txt\n",
      "Processing batch 5:  40%|████      | 4/10 [00:01<00:01,  3.10it/s]2024-07-23 00:17:24,632 - INFO - Processed and saved: preprocessed_data/main copy_cleaned.txt\n",
      "Processing batch 5:  50%|█████     | 5/10 [00:01<00:01,  3.12it/s]2024-07-23 00:17:24,848 - INFO - Processed and saved: preprocessed_data/jmedgenet-2016-103837_cleaned.txt\n",
      "Processing batch 5:  60%|██████    | 6/10 [00:01<00:01,  3.51it/s]2024-07-23 00:17:25,107 - INFO - Processed and saved: preprocessed_data/Acta Ophthalmologica - 2019 - Holtan - Inherited retinal disease in Norway   a characterization of current clinical and_cleaned.txt\n",
      "Processing batch 5:  70%|███████   | 7/10 [00:01<00:00,  3.62it/s]2024-07-23 00:17:26,219 - INFO - Processed and saved: preprocessed_data/1-s2.0-S1350946223000447-main_cleaned.txt\n",
      "Processing batch 5:  80%|████████  | 8/10 [00:03<00:01,  1.84it/s]2024-07-23 00:17:26,401 - INFO - Processed and saved: preprocessed_data/bjophthalmol-2020-315878_cleaned.txt\n",
      "Processing batch 5:  90%|█████████ | 9/10 [00:03<00:00,  2.33it/s]2024-07-23 00:17:26,633 - INFO - Processed and saved: preprocessed_data/fphar-12-654445_cleaned.txt\n",
      "Processing batch 5: 100%|██████████| 10/10 [00:03<00:00,  2.90it/s]\n",
      "2024-07-23 00:17:26,644 - INFO - Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"Loaded en_core_web_sm model\")\n",
    "\n",
    "# Custom stopwords - keep more words for readability\n",
    "custom_stopwords = set(stopwords.words('english')) - {'no', 'not', 'nor', 'against', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}\n",
    "\n",
    "def setup_logging(log_file='processing.log'):\n",
    "    \"\"\"Set up logging configuration.\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Basic text cleaning.\"\"\"\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def extract_important_phrases(text, n=100):\n",
    "    \"\"\"Extract important phrases using TF-IDF.\"\"\"\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 3), stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform([text])\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    tfidf_scores = tfidf_matrix.toarray()[0]\n",
    "    important_phrases = sorted(zip(feature_names, tfidf_scores), key=lambda x: x[1], reverse=True)[:n]\n",
    "    return [phrase for phrase, score in important_phrases]\n",
    "\n",
    "def identify_medical_entities(text):\n",
    "    \"\"\"Identify medical entities using spaCy.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    medical_entities = [ent.text for ent in doc.ents if ent.label_ in ['DISEASE', 'CHEMICAL', 'GENE']]\n",
    "    return list(set(medical_entities))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess the input text by cleaning and extracting important information.\"\"\"\n",
    "    try:\n",
    "        # Basic cleaning\n",
    "        cleaned_text = clean_text(text)\n",
    "        \n",
    "        # Extract important phrases\n",
    "        important_phrases = extract_important_phrases(cleaned_text)\n",
    "        \n",
    "        # Identify medical entities\n",
    "        medical_entities = identify_medical_entities(text)\n",
    "        \n",
    "        # Tokenize sentences\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        \n",
    "        # Process sentences\n",
    "        processed_sentences = []\n",
    "        for sent in sentences:\n",
    "            words = nltk.word_tokenize(sent)\n",
    "            preserved_words = [word for word in words \n",
    "                               if word.lower() not in custom_stopwords \n",
    "                               or word in important_phrases\n",
    "                               or word in medical_entities\n",
    "                               or word.isdigit()]\n",
    "            processed_sentences.append(' '.join(preserved_words))\n",
    "        \n",
    "        # Join processed sentences\n",
    "        processed_text = ' '.join(processed_sentences)\n",
    "        \n",
    "        return processed_text.strip()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in preprocess_text: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def process_papers(input_dir, output_dir, batch_size=10):\n",
    "    \"\"\"Process text files in batches in the input directory and save cleaned versions in the output directory.\"\"\"\n",
    "    try:\n",
    "        input_path = Path(input_dir)\n",
    "        output_path = Path(output_dir)\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        all_files = list(input_path.glob('*.txt'))\n",
    "        for i in range(0, len(all_files), batch_size):\n",
    "            batch = all_files[i:i+batch_size]\n",
    "            for text_file in tqdm(batch, desc=f\"Processing batch {i//batch_size + 1}\"):\n",
    "                try:\n",
    "                    with open(text_file, 'r', encoding='utf-8') as f:\n",
    "                        text = f.read()\n",
    "                    clean_text = preprocess_text(text)\n",
    "                    if clean_text:  # Ensure there's something to write\n",
    "                        output_file = output_path / f\"{text_file.stem}_cleaned.txt\"\n",
    "                        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                            f.write(clean_text)\n",
    "                        logging.info(f\"Processed and saved: {output_file}\")\n",
    "                    else:\n",
    "                        logging.warning(f\"No content to write for file: {text_file}\")\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing file {text_file}: {e}\")\n",
    "\n",
    "        logging.info(\"Processing complete.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in process_papers: {e}\")\n",
    "\n",
    "def main(input_dir, output_dir, batch_size):\n",
    "    \"\"\"Main function to set up logging and start the processing of papers.\"\"\"\n",
    "    setup_logging()\n",
    "    process_papers(input_dir, output_dir, batch_size)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_dir = './txt_data'\n",
    "    output_dir = './preprocessed_data'\n",
    "    batch_size = 10\n",
    "    main(input_dir, output_dir, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
