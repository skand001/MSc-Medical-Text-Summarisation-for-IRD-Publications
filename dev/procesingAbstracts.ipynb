{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from scispacy.linking import EntityLinker\n",
    "import scispacy\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import unicodedata\n",
    "import os\n",
    "import logging\n",
    "import chardet\n",
    "from collections import OrderedDict\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup completed.\n"
     ]
    }
   ],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "nlp = spacy.load(\"en_core_sci_md\")\n",
    "nlp.add_pipe(\"scispacy_linker\", last=True)\n",
    "\n",
    "print(\"Setup completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reassemble_hyphenated_words\n",
    "def reassemble_hyphenated_words(text):\n",
    "    return re.sub(r'(\\w+)-\\s*\\n(\\w+)', r'\\1\\2', text)\n",
    "\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "def remove_emails(text):\n",
    "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    return re.sub(email_pattern, '', text, flags=re.IGNORECASE)\n",
    "\n",
    "def remove_figures_tables(text):\n",
    "    return re.sub(r'\\b(figures?|tables?)\\b', '', text)\n",
    "\n",
    "def remove_numerical_references(text):\n",
    "    return re.sub(r'\\[\\d+\\]', '', text)\n",
    "\n",
    "def remove_citations(text):\n",
    "    patterns = [\n",
    "        r'\\b[A-Z][a-z]+\\s+[A-Z][a-z]+\\s+[A-Z][a-z]+\\s+et\\s+al\\.',\n",
    "        r'\\b[A-Z][a-z]+\\s+[A-Z][a-z]+\\s+et\\s+al\\.',\n",
    "        r'\\b[A-Z][a-z]+\\s+et\\s+al\\.',\n",
    "        r'\\(.*?et al\\..*?\\d{4}.*?\\)',\n",
    "        r'\\[.*?\\]',\n",
    "        r'\\(\\d{4}[a-z]?(?:,\\s*\\d{4}[a-z]?)*\\)',\n",
    "        r'^.*?\\d{4};.*?:\\s*\\d+.*?$',\n",
    "        r'^.*?\\d{4};.*?:\\s*\\d+.*?$',  # Matches journal info like \"2024;258: 119– 129\"\n",
    "    ]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        text = re.sub(pattern, '', text, flags=re.MULTILINE | re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "def remove_headers(text):\n",
    "    # Remove lines that are all uppercase and end with a colon\n",
    "    text = re.sub(r'^[A-Z\\s]+:$', '', text, flags=re.MULTILINE)\n",
    "    # Remove lines that start with bullet points\n",
    "    text = re.sub(r'^\\s*•.*$', '', text, flags=re.MULTILINE)\n",
    "    return text\n",
    "\n",
    "def remove_metadata(text):\n",
    "    # Remove headers, copyright info, DOI, received/accepted dates\n",
    "    patterns = [\n",
    "        r'^.*?©Copyright.*$',\n",
    "        r'^DOI:.*$',\n",
    "        r'^Received:.*$',\n",
    "        r'^Accepted:.*$',\n",
    "        r'^Address for Correspondence:.*$',\n",
    "        r'^E-mail:.*$',\n",
    "        r'^ORCID-ID:.*$',\n",
    "        r'^\\s*\\d+\\s*$',  # Page numbers\n",
    "        r'^.*?ORCID:.*$',\n",
    "        r'^Cite this article as:.*$',\n",
    "        r'\\[\\s*[^\\w\\s]*\\s*\\]'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        text = re.sub(pattern, '', text, flags=re.MULTILINE)\n",
    "    return text\n",
    "\n",
    "def remove_institution_names(text):\n",
    "    # Remove institution names (this is a simplified approach and may need refinement)\n",
    "    pattern = r'\\*+[A-Z][A-Za-z\\s,]+(University|Institute|Hospital|Department|Faculty)[^\\n]*'\n",
    "    return re.sub(pattern, '', text, flags=re.MULTILINE)\n",
    "\n",
    "def handle_special_characters(text):\n",
    "    \"\"\"Handle special characters and Unicode normalization.\"\"\"\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    char_map = {\n",
    "        '´': \"'\", '‘': \"'\", '’': \"'\", '“': '\"', '”': '\"', '–': '-', '—': '-', '…': '...'\n",
    "    }\n",
    "    for char, replacement in char_map.items():\n",
    "        text = text.replace(char, replacement)\n",
    "    return text\n",
    "\n",
    "def remove_copyright_info(text):\n",
    "    patterns = [\n",
    "        r'^©.*$',\n",
    "        r'Copyright.*$',\n",
    "        r'This is an open access article.*$',\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        text = re.sub(pattern, '', text, flags=re.MULTILINE | re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "def remove_doi_and_journal_info(text):\n",
    "    patterns = [\n",
    "        r'DOI:.*$',\n",
    "        r'^.*?\\d{4};\\d+:\\d+–\\d+',  # Matches journal info like \"2024;258: 119– 129\"\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        text = re.sub(pattern, '', text, flags=re.MULTILINE)\n",
    "    return text\n",
    "\n",
    "def remove_artifacts(text):\n",
    "    # Remove license and DOI information\n",
    "    text = re.sub(r'BY license \\(.*?\\)\\..*?commons\\.org/licenses/by/\\d\\.\\d/\\s*\\)\\.', '', text)\n",
    "    text = re.sub(r'://doi\\.org/\\d+\\.\\d+/[^\\s]+', '', text )\n",
    "    text = re.sub(r'://creativecommons\\.org/licenses/by/\\d\\.\\d/', '', text)\n",
    "    text = re.sub(r'://creativecommons\\.org/licenses/by-\\w+/\\d\\.\\d/', '', text)\n",
    "    \n",
    "    \n",
    "    # Remove unnecessary symbols\n",
    "    text = re.sub(r'[⁎\\]]', '', text)\n",
    "    \n",
    "    # Remove empty parentheses and brackets\n",
    "    text = re.sub(r'\\(\\s*\\)|\\[\\s*\\]', '', text)\n",
    "    \n",
    "    # Remove isolated semicolons\n",
    "    text = re.sub(r'\\s*;\\s*', ' ', text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def detect_sentence_boundaries(text):\n",
    "    \"\"\"\n",
    "    Detect sentence boundaries using spaCy.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    spacy_sentences = [sent.text for sent in doc.sents]\n",
    "    return ' '.join(spacy_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    \"\"\"Count the number of words in the given text.\"\"\"\n",
    "    # Split on word boundaries\n",
    "    words = re.findall(r'\\b[\\w\\'-]+\\b', text)\n",
    "    # Filter out purely numeric \"words\"\n",
    "    return len([word for word in words if not word.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_abstract_and_main_text(text):\n",
    "    # Possible sections indicating the beginning of the abstract\n",
    "    abstract_start_patterns = [\n",
    "        r'\\bAbstract\\b',\n",
    "        r'\\bBackground\\b',\n",
    "        r'\\bPurpose\\b'\n",
    "    ]\n",
    "    \n",
    "    # Possible sections indicating the end of the abstract\n",
    "    abstract_end_patterns = [\n",
    "        r'\\bKeywords\\b',\n",
    "        r'\\bIntroduction\\b'\n",
    "    ]\n",
    "    \n",
    "    # Initialize abstract boundaries\n",
    "    abstract_start = None\n",
    "    abstract_end = None\n",
    "    \n",
    "    # Search for the start of the abstract using standard patterns\n",
    "    for pattern in abstract_start_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            abstract_start = match.end()\n",
    "            break\n",
    "    \n",
    "    # If no start pattern is found, assume the abstract starts after any metadata or headers\n",
    "    if not abstract_start:\n",
    "        lines = text.splitlines()\n",
    "        for line in lines:\n",
    "            if re.search(r'\\bAuthor[s]?|Acknowledgment[s]?|Declaration[s]?\\b', line, re.IGNORECASE):\n",
    "                continue\n",
    "            if len(line.strip()) > 30 and not re.search(r'\\[\\d+\\]', line):\n",
    "                abstract_start = text.find(line)\n",
    "                break\n",
    "\n",
    "    # Exit if we cannot determine the start of the abstract\n",
    "    if abstract_start is None:\n",
    "        return \"Abstract not found.\", text\n",
    "    \n",
    "    # Search for the end of the abstract\n",
    "    for pattern in abstract_end_patterns:\n",
    "        match = re.search(pattern, text[abstract_start:], re.IGNORECASE)\n",
    "        if match:\n",
    "            abstract_end = abstract_start + match.start()\n",
    "            break\n",
    "    \n",
    "    # Default to the end of the text if no clear end pattern is found\n",
    "    if not abstract_end:\n",
    "        abstract_end = len(text)\n",
    "    \n",
    "    # Extract the abstract content\n",
    "    abstract = text[abstract_start:abstract_end].strip()\n",
    "    \n",
    "    # Extract the main text starting from the end of the abstract\n",
    "    main_text = text[abstract_end:].strip()\n",
    "\n",
    "    # Optionally, limit the abstract to a certain number of words\n",
    "    max_words = 250\n",
    "    words = abstract.split()\n",
    "    if len(words) > max_words:\n",
    "        abstract = ' '.join(words[:max_words])\n",
    "    \n",
    "    return abstract, main_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    try:\n",
    "        print(f\"Starting preprocessing...\")\n",
    "        initial_word_count = count_words(text)\n",
    "        print(f\"Initial word count: {initial_word_count}\")\n",
    "\n",
    "        # Extract abstract\n",
    "        abstract, main_text = extract_abstract_and_main_text(text)\n",
    "        print(f\"Abstract extracted. Abstract word count: {count_words(abstract)}\")\n",
    "        print(f\"Main text word count: {count_words(main_text)}\")\n",
    "\n",
    "        # Step 1: Initial text cleaning\n",
    "        main_text = reassemble_hyphenated_words(main_text)\n",
    "        print(f\"After reassemble_hyphenated_words: {count_words(main_text)} words\")\n",
    "\n",
    "        main_text = remove_figures_tables(main_text)\n",
    "        print(f\"After remove_figures_tables: {count_words(main_text)} words\")\n",
    "\n",
    "        main_text = remove_citations(main_text)\n",
    "        print(f\"After remove_citations: {count_words(main_text)} words\")\n",
    "\n",
    "        main_text = remove_urls(main_text)\n",
    "        print(f\"After remove_urls: {count_words(main_text)} words\")\n",
    "\n",
    "        main_text = remove_emails(main_text)\n",
    "        print(f\"After remove_emails: {count_words(main_text)} words\")\n",
    "\n",
    "        main_text = remove_numerical_references(main_text)\n",
    "        print(f\"After remove_numerical_references: {count_words(main_text)} words\")\n",
    "\n",
    "        main_text = remove_headers(main_text)\n",
    "        print(f\"After remove_headers: {count_words(main_text)} words\")\n",
    "\n",
    "        main_text = remove_metadata(main_text)\n",
    "        print(f\"After remove_metadata: {count_words(main_text)} words\")\n",
    "\n",
    "        main_text = remove_institution_names(main_text)\n",
    "        print(f\"After remove_institution_names: {count_words(main_text)} words\")\n",
    "        \n",
    "        main_text = remove_copyright_info(main_text)\n",
    "        print(f\"After remove_copyright_info: {count_words(main_text)} words\")\n",
    "\n",
    "        main_text = remove_doi_and_journal_info(main_text)\n",
    "        print(f\"After remove_doi_and_journal_info: {count_words(main_text)} words\")\n",
    "\n",
    "        main_text = remove_artifacts(main_text)\n",
    "        print(f\"After remove_artifacts: {count_words(main_text)} words\")\n",
    "\n",
    "        # Remove extra whitespace\n",
    "        main_text = ' '.join(main_text.split())\n",
    "        print(f\"After removing extra whitespace: {count_words(main_text)} words\")\n",
    "    \n",
    "        main_text = handle_special_characters(main_text)\n",
    "        print(f\"After handle_special_characters: {count_words(main_text)} words\")\n",
    "\n",
    "        main_text = detect_sentence_boundaries(main_text)\n",
    "        print(f\"After detect_sentence_boundaries: {count_words(main_text)} words\")\n",
    "\n",
    "        final_word_count = count_words(main_text)\n",
    "        print(f\"Final preprocessed word count: {final_word_count}\")\n",
    "\n",
    "        if initial_word_count > 0:\n",
    "            percentage_retained = (final_word_count / initial_word_count) * 100\n",
    "            print(f\"Percentage of words retained after cleaning: {percentage_retained:.2f}%\")\n",
    "        else:\n",
    "            print(\"Original text contains no words; cannot calculate percentage.\")\n",
    "\n",
    "        return abstract, main_text.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in preprocess_text: {e}\")\n",
    "        return None, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chardet\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "def process_files(input_folder_path: str, output_folder_path: str, batch_size: int = 10) -> None:\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "\n",
    "    files = [f for f in os.listdir(input_folder_path) if f.endswith('.txt')]\n",
    "    total_files = len(files)\n",
    "\n",
    "    for i in range(0, total_files, batch_size):\n",
    "        batch = files[i:i+batch_size]\n",
    "        print(f\"\\nProcessing batch {i//batch_size + 1} of {(total_files-1)//batch_size + 1}\")\n",
    "\n",
    "        for filename in tqdm(batch, desc=f\"Batch {i//batch_size + 1}\"):\n",
    "            input_file_path = os.path.join(input_folder_path, filename)\n",
    "            output_file_path = os.path.join(output_folder_path, f\"processed_{filename}\")\n",
    "\n",
    "            print(f\"\\nProcessing file: {filename}\")\n",
    "\n",
    "            try:\n",
    "                with open(input_file_path, 'rb') as file:\n",
    "                    raw_data = file.read()\n",
    "                    result = chardet.detect(raw_data)\n",
    "                    detected_encoding = result['encoding']\n",
    "                    confidence = result['confidence']\n",
    "\n",
    "                with open(input_file_path, 'r', encoding=detected_encoding or 'utf-8') as file:\n",
    "                    original_text = file.read()\n",
    "\n",
    "                # Extract abstract and clean main text\n",
    "                abstract, cleaned_text = preprocess_text(original_text)\n",
    "\n",
    "                # Prepare output text\n",
    "                output_text = f\"Abstract:\\n{abstract}\\n\\nMain Text:\\n{cleaned_text}\"\n",
    "\n",
    "                # Write the cleaned text and abstract to the output file\n",
    "                with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "                    file.write(output_text)\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing file {filename}: {str(e)}\")\n",
    "\n",
    "            print(\"=\" * 100)\n",
    "\n",
    "        print(f\"Completed processing batch {i//batch_size + 1}\")\n",
    "\n",
    "    print(\"All batches processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_frequent_terms(text, n=10, min_length=3):\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    words = re.findall(r'\\b[a-zA-Z]{' + str(min_length) + r',}\\b', text.lower())\n",
    "    \n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Count word frequencies\n",
    "    word_freq = Counter(words)\n",
    "    \n",
    "    # Return the n most common words with their counts\n",
    "    return word_freq.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing batch 1 of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: 10.1177_2515841420954592.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 14885\n",
      "Abstract extracted. Abstract word count: 177\n",
      "Main text word count: 14313\n",
      "After reassemble_hyphenated_words: 14281 words\n",
      "After remove_figures_tables: 14280 words\n",
      "After remove_citations: 13116 words\n",
      "After remove_urls: 12923 words\n",
      "After remove_emails: 12918 words\n",
      "After remove_numerical_references: 12918 words\n",
      "After remove_headers: 12475 words\n",
      "After remove_metadata: 12475 words\n",
      "After remove_institution_names: 12475 words\n",
      "After remove_copyright_info: 12475 words\n",
      "After remove_doi_and_journal_info: 12471 words\n",
      "After remove_artifacts: 12471 words\n",
      "After removing extra whitespace: 12471 words\n",
      "After handle_special_characters: 12447 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1:  10%|█         | 1/10 [00:02<00:23,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 12447 words\n",
      "Final preprocessed word count: 12447\n",
      "Percentage of words retained after cleaning: 83.62%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: 13287_2023_Article_3526.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 6492\n",
      "Abstract extracted. Abstract word count: 199\n",
      "Main text word count: 6159\n",
      "After reassemble_hyphenated_words: 6135 words\n",
      "After remove_figures_tables: 6135 words\n",
      "After remove_citations: 5663 words\n",
      "After remove_urls: 5648 words\n",
      "After remove_emails: 5645 words\n",
      "After remove_numerical_references: 5645 words\n",
      "After remove_headers: 5645 words\n",
      "After remove_metadata: 5641 words\n",
      "After remove_institution_names: 5641 words\n",
      "After remove_copyright_info: 5616 words\n",
      "After remove_doi_and_journal_info: 5616 words\n",
      "After remove_artifacts: 5616 words\n",
      "After removing extra whitespace: 5616 words\n",
      "After handle_special_characters: 5600 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1:  20%|██        | 2/10 [00:03<00:14,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 5600 words\n",
      "Final preprocessed word count: 5600\n",
      "Percentage of words retained after cleaning: 86.26%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: ijms-22-05684.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 14383\n",
      "Abstract extracted. Abstract word count: 195\n",
      "Main text word count: 14025\n",
      "After reassemble_hyphenated_words: 13986 words\n",
      "After remove_figures_tables: 13986 words\n",
      "After remove_citations: 13737 words\n",
      "After remove_urls: 13687 words\n",
      "After remove_emails: 13687 words\n",
      "After remove_numerical_references: 13687 words\n",
      "After remove_headers: 13687 words\n",
      "After remove_metadata: 13687 words\n",
      "After remove_institution_names: 13687 words\n",
      "After remove_copyright_info: 13687 words\n",
      "After remove_doi_and_journal_info: 13687 words\n",
      "After remove_artifacts: 13687 words\n",
      "After removing extra whitespace: 13687 words\n",
      "After handle_special_characters: 13652 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1:  30%|███       | 3/10 [00:06<00:15,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 13652 words\n",
      "Final preprocessed word count: 13652\n",
      "Percentage of words retained after cleaning: 94.92%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: bjophthalmol-2020-315878.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 4383\n",
      "Abstract extracted. Abstract word count: 198\n",
      "Main text word count: 4012\n",
      "After reassemble_hyphenated_words: 3992 words\n",
      "After remove_figures_tables: 3987 words\n",
      "After remove_citations: 3716 words\n",
      "After remove_urls: 3709 words\n",
      "After remove_emails: 3709 words\n",
      "After remove_numerical_references: 3709 words\n",
      "After remove_headers: 3709 words\n",
      "After remove_metadata: 3709 words\n",
      "After remove_institution_names: 3709 words\n",
      "After remove_copyright_info: 3698 words\n",
      "After remove_doi_and_journal_info: 3698 words\n",
      "After remove_artifacts: 3698 words\n",
      "After removing extra whitespace: 3698 words\n",
      "After handle_special_characters: 3693 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1:  40%|████      | 4/10 [00:07<00:10,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 3693 words\n",
      "Final preprocessed word count: 3693\n",
      "Percentage of words retained after cleaning: 84.26%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: iovs-63-2-11.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 5734\n",
      "Abstract extracted. Abstract word count: 261\n",
      "Main text word count: 5332\n",
      "After reassemble_hyphenated_words: 5233 words\n",
      "After remove_figures_tables: 5233 words\n",
      "After remove_citations: 4887 words\n",
      "After remove_urls: 4887 words\n",
      "After remove_emails: 4887 words\n",
      "After remove_numerical_references: 4887 words\n",
      "After remove_headers: 4887 words\n",
      "After remove_metadata: 4887 words\n",
      "After remove_institution_names: 4887 words\n",
      "After remove_copyright_info: 4884 words\n",
      "After remove_doi_and_journal_info: 4884 words\n",
      "After remove_artifacts: 4884 words\n",
      "After removing extra whitespace: 4884 words\n",
      "After handle_special_characters: 4878 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1:  50%|█████     | 5/10 [00:08<00:07,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 4878 words\n",
      "Final preprocessed word count: 4878\n",
      "Percentage of words retained after cleaning: 85.07%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: EMMM-14-e15941-compressed.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 13488\n",
      "Abstract extracted. Abstract word count: 195\n",
      "Main text word count: 13237\n",
      "After reassemble_hyphenated_words: 13162 words\n",
      "After remove_figures_tables: 13159 words\n",
      "After remove_citations: 12949 words\n",
      "After remove_urls: 12925 words\n",
      "After remove_emails: 12914 words\n",
      "After remove_numerical_references: 12914 words\n",
      "After remove_headers: 12914 words\n",
      "After remove_metadata: 12914 words\n",
      "After remove_institution_names: 12914 words\n",
      "After remove_copyright_info: 12906 words\n",
      "After remove_doi_and_journal_info: 12906 words\n",
      "After remove_artifacts: 12906 words\n",
      "After removing extra whitespace: 12906 words\n",
      "After handle_special_characters: 12837 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1:  60%|██████    | 6/10 [00:11<00:07,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 12837 words\n",
      "Final preprocessed word count: 12837\n",
      "Percentage of words retained after cleaning: 95.17%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: jci-133-171356.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 11482\n",
      "Abstract extracted. Abstract word count: 232\n",
      "Main text word count: 2129\n",
      "After reassemble_hyphenated_words: 2109 words\n",
      "After remove_figures_tables: 2109 words\n",
      "After remove_citations: 2000 words\n",
      "After remove_urls: 1995 words\n",
      "After remove_emails: 1991 words\n",
      "After remove_numerical_references: 1991 words\n",
      "After remove_headers: 1991 words\n",
      "After remove_metadata: 1991 words\n",
      "After remove_institution_names: 1991 words\n",
      "After remove_copyright_info: 1991 words\n",
      "After remove_doi_and_journal_info: 1991 words\n",
      "After remove_artifacts: 1991 words\n",
      "After removing extra whitespace: 1991 words\n",
      "After handle_special_characters: 1974 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1:  70%|███████   | 7/10 [00:14<00:07,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 1974 words\n",
      "Final preprocessed word count: 1974\n",
      "Percentage of words retained after cleaning: 17.19%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: 12886_2023_Article_2772-compressed.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 4683\n",
      "Abstract extracted. Abstract word count: 220\n",
      "Main text word count: 4078\n",
      "After reassemble_hyphenated_words: 4067 words\n",
      "After remove_figures_tables: 4067 words\n",
      "After remove_citations: 3931 words\n",
      "After remove_urls: 3930 words\n",
      "After remove_emails: 3928 words\n",
      "After remove_numerical_references: 3928 words\n",
      "After remove_headers: 3928 words\n",
      "After remove_metadata: 3924 words\n",
      "After remove_institution_names: 3924 words\n",
      "After remove_copyright_info: 3924 words\n",
      "After remove_doi_and_journal_info: 3924 words\n",
      "After remove_artifacts: 3924 words\n",
      "After removing extra whitespace: 3924 words\n",
      "After handle_special_characters: 3913 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1:  80%|████████  | 8/10 [00:15<00:03,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 3913 words\n",
      "Final preprocessed word count: 3913\n",
      "Percentage of words retained after cleaning: 83.56%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: genes-12-00147.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 8521\n",
      "Abstract extracted. Abstract word count: 149\n",
      "Main text word count: 8123\n",
      "After reassemble_hyphenated_words: 8091 words\n",
      "After remove_figures_tables: 8091 words\n",
      "After remove_citations: 7951 words\n",
      "After remove_urls: 7934 words\n",
      "After remove_emails: 7934 words\n",
      "After remove_numerical_references: 7934 words\n",
      "After remove_headers: 7934 words\n",
      "After remove_metadata: 7934 words\n",
      "After remove_institution_names: 7934 words\n",
      "After remove_copyright_info: 7934 words\n",
      "After remove_doi_and_journal_info: 7934 words\n",
      "After remove_artifacts: 7934 words\n",
      "After removing extra whitespace: 7934 words\n",
      "After handle_special_characters: 7895 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1:  90%|█████████ | 9/10 [00:17<00:01,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 7895 words\n",
      "Final preprocessed word count: 7895\n",
      "Percentage of words retained after cleaning: 92.65%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: nihms-1927912.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 9916\n",
      "Abstract extracted. Abstract word count: 109\n",
      "Main text word count: 9670\n",
      "After reassemble_hyphenated_words: 9662 words\n",
      "After remove_figures_tables: 9660 words\n",
      "After remove_citations: 9498 words\n",
      "After remove_urls: 9490 words\n",
      "After remove_emails: 9486 words\n",
      "After remove_numerical_references: 9486 words\n",
      "After remove_headers: 9486 words\n",
      "After remove_metadata: 9486 words\n",
      "After remove_institution_names: 9486 words\n",
      "After remove_copyright_info: 9486 words\n",
      "After remove_doi_and_journal_info: 9486 words\n",
      "After remove_artifacts: 9486 words\n",
      "After removing extra whitespace: 9486 words\n",
      "After handle_special_characters: 9477 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1: 100%|██████████| 10/10 [00:19<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 9477 words\n",
      "Final preprocessed word count: 9477\n",
      "Percentage of words retained after cleaning: 95.57%\n",
      "====================================================================================================\n",
      "Completed processing batch 1\n",
      "\n",
      "Processing batch 2 of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: 13023_2021_Article_2145.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 6208\n",
      "Abstract extracted. Abstract word count: 133\n",
      "Main text word count: 6038\n",
      "After reassemble_hyphenated_words: 6017 words\n",
      "After remove_figures_tables: 6017 words\n",
      "After remove_citations: 5779 words\n",
      "After remove_urls: 5759 words\n",
      "After remove_emails: 5755 words\n",
      "After remove_numerical_references: 5755 words\n",
      "After remove_headers: 5755 words\n",
      "After remove_metadata: 5751 words\n",
      "After remove_institution_names: 5751 words\n",
      "After remove_copyright_info: 5726 words\n",
      "After remove_doi_and_journal_info: 5726 words\n",
      "After remove_artifacts: 5726 words\n",
      "After removing extra whitespace: 5726 words\n",
      "After handle_special_characters: 5709 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2:  10%|█         | 1/10 [00:01<00:10,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 5709 words\n",
      "Final preprocessed word count: 5709\n",
      "Percentage of words retained after cleaning: 91.96%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: jcm-12-06953.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 11423\n",
      "Abstract extracted. Abstract word count: 176\n",
      "Main text word count: 11133\n",
      "After reassemble_hyphenated_words: 11103 words\n",
      "After remove_figures_tables: 11103 words\n",
      "After remove_citations: 10854 words\n",
      "After remove_urls: 10844 words\n",
      "After remove_emails: 10844 words\n",
      "After remove_numerical_references: 10844 words\n",
      "After remove_headers: 10844 words\n",
      "After remove_metadata: 10844 words\n",
      "After remove_institution_names: 10844 words\n",
      "After remove_copyright_info: 10844 words\n",
      "After remove_doi_and_journal_info: 10844 words\n",
      "After remove_artifacts: 10844 words\n",
      "After removing extra whitespace: 10844 words\n",
      "After handle_special_characters: 10823 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2:  20%|██        | 2/10 [00:03<00:14,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 10823 words\n",
      "Final preprocessed word count: 10823\n",
      "Percentage of words retained after cleaning: 94.75%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: IJO-70-2316.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 7953\n",
      "Abstract extracted. Abstract word count: 133\n",
      "Main text word count: 7820\n",
      "After reassemble_hyphenated_words: 7820 words\n",
      "After remove_figures_tables: 7820 words\n",
      "After remove_citations: 7508 words\n",
      "After remove_urls: 7491 words\n",
      "After remove_emails: 7485 words\n",
      "After remove_numerical_references: 7485 words\n",
      "After remove_headers: 7485 words\n",
      "After remove_metadata: 7456 words\n",
      "After remove_institution_names: 7456 words\n",
      "After remove_copyright_info: 7456 words\n",
      "After remove_doi_and_journal_info: 7456 words\n",
      "After remove_artifacts: 7456 words\n",
      "After removing extra whitespace: 7456 words\n",
      "After handle_special_characters: 7217 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2:  30%|███       | 3/10 [00:04<00:11,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 7217 words\n",
      "Final preprocessed word count: 7217\n",
      "Percentage of words retained after cleaning: 90.75%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: TJO-53-44.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 9202\n",
      "Abstract extracted. Abstract word count: 71\n",
      "Main text word count: 8960\n",
      "After reassemble_hyphenated_words: 8951 words\n",
      "After remove_figures_tables: 8951 words\n",
      "After remove_citations: 8619 words\n",
      "After remove_urls: 8619 words\n",
      "After remove_emails: 8616 words\n",
      "After remove_numerical_references: 8616 words\n",
      "After remove_headers: 8169 words\n",
      "After remove_metadata: 8127 words\n",
      "After remove_institution_names: 8127 words\n",
      "After remove_copyright_info: 8125 words\n",
      "After remove_doi_and_journal_info: 8125 words\n",
      "After remove_artifacts: 8125 words\n",
      "After removing extra whitespace: 8125 words\n",
      "After handle_special_characters: 8122 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2:  40%|████      | 4/10 [00:06<00:10,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 8122 words\n",
      "Final preprocessed word count: 8122\n",
      "Percentage of words retained after cleaning: 88.26%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: biomolecules-12-00455-compressed.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 14007\n",
      "Abstract extracted. Abstract word count: 253\n",
      "Main text word count: 13463\n",
      "After reassemble_hyphenated_words: 13366 words\n",
      "After remove_figures_tables: 13366 words\n",
      "After remove_citations: 13239 words\n",
      "After remove_urls: 13223 words\n",
      "After remove_emails: 13223 words\n",
      "After remove_numerical_references: 13223 words\n",
      "After remove_headers: 13223 words\n",
      "After remove_metadata: 13223 words\n",
      "After remove_institution_names: 13223 words\n",
      "After remove_copyright_info: 13223 words\n",
      "After remove_doi_and_journal_info: 13223 words\n",
      "After remove_artifacts: 13223 words\n",
      "After removing extra whitespace: 13223 words\n",
      "After handle_special_characters: 13092 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2:  50%|█████     | 5/10 [00:09<00:10,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 13092 words\n",
      "Final preprocessed word count: 13092\n",
      "Percentage of words retained after cleaning: 93.47%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: 1-s2.0-S1350946223000447-main.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 34518\n",
      "Abstract extracted. Abstract word count: 182\n",
      "Main text word count: 34215\n",
      "After reassemble_hyphenated_words: 34025 words\n",
      "After remove_figures_tables: 34025 words\n",
      "After remove_citations: 32695 words\n",
      "After remove_urls: 32690 words\n",
      "After remove_emails: 32680 words\n",
      "After remove_numerical_references: 32680 words\n",
      "After remove_headers: 32680 words\n",
      "After remove_metadata: 32680 words\n",
      "After remove_institution_names: 32680 words\n",
      "After remove_copyright_info: 32680 words\n",
      "After remove_doi_and_journal_info: 32680 words\n",
      "After remove_artifacts: 32680 words\n",
      "After removing extra whitespace: 32680 words\n",
      "After handle_special_characters: 32634 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2:  60%|██████    | 6/10 [00:18<00:17,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 32634 words\n",
      "Final preprocessed word count: 32634\n",
      "Percentage of words retained after cleaning: 94.54%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: jmedgenet-2016-103837.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 6064\n",
      "Abstract extracted. Abstract word count: 214\n",
      "Main text word count: 5720\n",
      "After reassemble_hyphenated_words: 5693 words\n",
      "After remove_figures_tables: 5674 words\n",
      "After remove_citations: 5347 words\n",
      "After remove_urls: 5338 words\n",
      "After remove_emails: 5338 words\n",
      "After remove_numerical_references: 5338 words\n",
      "After remove_headers: 5338 words\n",
      "After remove_metadata: 5338 words\n",
      "After remove_institution_names: 5338 words\n",
      "After remove_copyright_info: 5327 words\n",
      "After remove_doi_and_journal_info: 5327 words\n",
      "After remove_artifacts: 5327 words\n",
      "After removing extra whitespace: 5327 words\n",
      "After handle_special_characters: 5322 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2:  70%|███████   | 7/10 [00:19<00:09,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 5322 words\n",
      "Final preprocessed word count: 5322\n",
      "Percentage of words retained after cleaning: 87.76%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: 41433_2022_Article_2262.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 3318\n",
      "Abstract extracted. Abstract word count: 245\n",
      "Main text word count: 3026\n",
      "After reassemble_hyphenated_words: 3015 words\n",
      "After remove_figures_tables: 3015 words\n",
      "After remove_citations: 2862 words\n",
      "After remove_urls: 2853 words\n",
      "After remove_emails: 2848 words\n",
      "After remove_numerical_references: 2848 words\n",
      "After remove_headers: 2848 words\n",
      "After remove_metadata: 2842 words\n",
      "After remove_institution_names: 2842 words\n",
      "After remove_copyright_info: 2842 words\n",
      "After remove_doi_and_journal_info: 2842 words\n",
      "After remove_artifacts: 2842 words\n",
      "After removing extra whitespace: 2842 words\n",
      "After handle_special_characters: 2841 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2:  80%|████████  | 8/10 [00:19<00:04,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 2841 words\n",
      "Final preprocessed word count: 2841\n",
      "Percentage of words retained after cleaning: 85.62%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: emss-80329.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 13597\n",
      "Abstract extracted. Abstract word count: 143\n",
      "Main text word count: 13399\n",
      "After reassemble_hyphenated_words: 13378 words\n",
      "After remove_figures_tables: 13378 words\n",
      "After remove_citations: 11852 words\n",
      "After remove_urls: 11852 words\n",
      "After remove_emails: 11847 words\n",
      "After remove_numerical_references: 11847 words\n",
      "After remove_headers: 11847 words\n",
      "After remove_metadata: 11847 words\n",
      "After remove_institution_names: 11847 words\n",
      "After remove_copyright_info: 11847 words\n",
      "After remove_doi_and_journal_info: 11847 words\n",
      "After remove_artifacts: 11847 words\n",
      "After removing extra whitespace: 11847 words\n",
      "After handle_special_characters: 11814 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2:  90%|█████████ | 9/10 [00:22<00:02,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 11814 words\n",
      "Final preprocessed word count: 11814\n",
      "Percentage of words retained after cleaning: 86.89%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: nihms-1747988.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 2102\n",
      "Abstract extracted. Abstract word count: 191\n",
      "Main text word count: 1584\n",
      "After reassemble_hyphenated_words: 1583 words\n",
      "After remove_figures_tables: 1583 words\n",
      "After remove_citations: 1495 words\n",
      "After remove_urls: 1490 words\n",
      "After remove_emails: 1490 words\n",
      "After remove_numerical_references: 1490 words\n",
      "After remove_headers: 1490 words\n",
      "After remove_metadata: 1490 words\n",
      "After remove_institution_names: 1490 words\n",
      "After remove_copyright_info: 1490 words\n",
      "After remove_doi_and_journal_info: 1490 words\n",
      "After remove_artifacts: 1490 words\n",
      "After removing extra whitespace: 1490 words\n",
      "After handle_special_characters: 1488 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2: 100%|██████████| 10/10 [00:22<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 1488 words\n",
      "Final preprocessed word count: 1488\n",
      "Percentage of words retained after cleaning: 70.79%\n",
      "====================================================================================================\n",
      "Completed processing batch 2\n",
      "\n",
      "Processing batch 3 of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: TJP-600-4623.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 6963\n",
      "Abstract extracted. Abstract word count: 258\n",
      "Main text word count: 39\n",
      "After reassemble_hyphenated_words: 39 words\n",
      "After remove_figures_tables: 39 words\n",
      "After remove_citations: 39 words\n",
      "After remove_urls: 39 words\n",
      "After remove_emails: 39 words\n",
      "After remove_numerical_references: 39 words\n",
      "After remove_headers: 39 words\n",
      "After remove_metadata: 39 words\n",
      "After remove_institution_names: 39 words\n",
      "After remove_copyright_info: 21 words\n",
      "After remove_doi_and_journal_info: 21 words\n",
      "After remove_artifacts: 21 words\n",
      "After removing extra whitespace: 21 words\n",
      "After handle_special_characters: 21 words\n",
      "After detect_sentence_boundaries: 21 words\n",
      "Final preprocessed word count: 21\n",
      "Percentage of words retained after cleaning: 0.30%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: main (1).txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 5884\n",
      "Abstract extracted. Abstract word count: 251\n",
      "Main text word count: 5252\n",
      "After reassemble_hyphenated_words: 5111 words\n",
      "After remove_figures_tables: 5111 words\n",
      "After remove_citations: 4927 words\n",
      "After remove_urls: 4922 words\n",
      "After remove_emails: 4922 words\n",
      "After remove_numerical_references: 4922 words\n",
      "After remove_headers: 4747 words\n",
      "After remove_metadata: 4747 words\n",
      "After remove_institution_names: 4747 words\n",
      "After remove_copyright_info: 4736 words\n",
      "After remove_doi_and_journal_info: 4736 words\n",
      "After remove_artifacts: 4736 words\n",
      "After removing extra whitespace: 4736 words\n",
      "After handle_special_characters: 4709 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3:  20%|██        | 2/10 [00:01<00:04,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 4709 words\n",
      "Final preprocessed word count: 4709\n",
      "Percentage of words retained after cleaning: 80.03%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: ijms-22-04534.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 11997\n",
      "Abstract extracted. Abstract word count: 198\n",
      "Main text word count: 11401\n",
      "After reassemble_hyphenated_words: 11346 words\n",
      "After remove_figures_tables: 11346 words\n",
      "After remove_citations: 11141 words\n",
      "After remove_urls: 11131 words\n",
      "After remove_emails: 11131 words\n",
      "After remove_numerical_references: 11131 words\n",
      "After remove_headers: 11131 words\n",
      "After remove_metadata: 11131 words\n",
      "After remove_institution_names: 11131 words\n",
      "After remove_copyright_info: 11131 words\n",
      "After remove_doi_and_journal_info: 11131 words\n",
      "After remove_artifacts: 11131 words\n",
      "After removing extra whitespace: 11131 words\n",
      "After handle_special_characters: 11101 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3:  30%|███       | 3/10 [00:03<00:08,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 11101 words\n",
      "Final preprocessed word count: 11101\n",
      "Percentage of words retained after cleaning: 92.53%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: 41436_2020_Article_759.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 6235\n",
      "Abstract extracted. Abstract word count: 212\n",
      "Main text word count: 5964\n",
      "After reassemble_hyphenated_words: 5941 words\n",
      "After remove_figures_tables: 5941 words\n",
      "After remove_citations: 5613 words\n",
      "After remove_urls: 5587 words\n",
      "After remove_emails: 5583 words\n",
      "After remove_numerical_references: 5583 words\n",
      "After remove_headers: 5583 words\n",
      "After remove_metadata: 5583 words\n",
      "After remove_institution_names: 5583 words\n",
      "After remove_copyright_info: 5567 words\n",
      "After remove_doi_and_journal_info: 5567 words\n",
      "After remove_artifacts: 5567 words\n",
      "After removing extra whitespace: 5567 words\n",
      "After handle_special_characters: 5566 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3:  40%|████      | 4/10 [00:04<00:07,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 5566 words\n",
      "Final preprocessed word count: 5566\n",
      "Percentage of words retained after cleaning: 89.27%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: JCO-34-80.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 4720\n",
      "Abstract extracted. Abstract word count: 214\n",
      "Main text word count: 4390\n",
      "After reassemble_hyphenated_words: 4390 words\n",
      "After remove_figures_tables: 4389 words\n",
      "After remove_citations: 4227 words\n",
      "After remove_urls: 4224 words\n",
      "After remove_emails: 4218 words\n",
      "After remove_numerical_references: 4218 words\n",
      "After remove_headers: 4218 words\n",
      "After remove_metadata: 4217 words\n",
      "After remove_institution_names: 4217 words\n",
      "After remove_copyright_info: 4217 words\n",
      "After remove_doi_and_journal_info: 4217 words\n",
      "After remove_artifacts: 4217 words\n",
      "After removing extra whitespace: 4217 words\n",
      "After handle_special_characters: 4166 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3:  50%|█████     | 5/10 [00:05<00:05,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 4166 words\n",
      "Final preprocessed word count: 4166\n",
      "Percentage of words retained after cleaning: 88.26%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: opth-16-1127.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 5248\n",
      "Abstract extracted. Abstract word count: 215\n",
      "Main text word count: 4937\n",
      "After reassemble_hyphenated_words: 4930 words\n",
      "After remove_figures_tables: 4928 words\n",
      "After remove_citations: 4686 words\n",
      "After remove_urls: 4555 words\n",
      "After remove_emails: 4555 words\n",
      "After remove_numerical_references: 4555 words\n",
      "After remove_headers: 4555 words\n",
      "After remove_metadata: 4551 words\n",
      "After remove_institution_names: 4551 words\n",
      "After remove_copyright_info: 4531 words\n",
      "After remove_doi_and_journal_info: 4531 words\n",
      "After remove_artifacts: 4531 words\n",
      "After removing extra whitespace: 4531 words\n",
      "After handle_special_characters: 4507 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3:  60%|██████    | 6/10 [00:06<00:04,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 4507 words\n",
      "Final preprocessed word count: 4507\n",
      "Percentage of words retained after cleaning: 85.88%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: MGG3-9-e1663.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 5569\n",
      "Abstract extracted. Abstract word count: 25\n",
      "Main text word count: 5299\n",
      "After reassemble_hyphenated_words: 5216 words\n",
      "After remove_figures_tables: 5216 words\n",
      "After remove_citations: 5126 words\n",
      "After remove_urls: 5032 words\n",
      "After remove_emails: 5032 words\n",
      "After remove_numerical_references: 5032 words\n",
      "After remove_headers: 5032 words\n",
      "After remove_metadata: 5032 words\n",
      "After remove_institution_names: 5032 words\n",
      "After remove_copyright_info: 5032 words\n",
      "After remove_doi_and_journal_info: 5032 words\n",
      "After remove_artifacts: 5032 words\n",
      "After removing extra whitespace: 5032 words\n",
      "After handle_special_characters: 5028 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3:  80%|████████  | 8/10 [00:07<00:01,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 5028 words\n",
      "Final preprocessed word count: 5028\n",
      "Percentage of words retained after cleaning: 90.29%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: main copy.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 6262\n",
      "Abstract extracted. Abstract word count: 224\n",
      "Main text word count: 854\n",
      "After reassemble_hyphenated_words: 841 words\n",
      "After remove_figures_tables: 841 words\n",
      "After remove_citations: 623 words\n",
      "After remove_urls: 617 words\n",
      "After remove_emails: 612 words\n",
      "After remove_numerical_references: 612 words\n",
      "After remove_headers: 612 words\n",
      "After remove_metadata: 612 words\n",
      "After remove_institution_names: 612 words\n",
      "After remove_copyright_info: 612 words\n",
      "After remove_doi_and_journal_info: 612 words\n",
      "After remove_artifacts: 612 words\n",
      "After removing extra whitespace: 612 words\n",
      "After handle_special_characters: 612 words\n",
      "After detect_sentence_boundaries: 612 words\n",
      "Final preprocessed word count: 612\n",
      "Percentage of words retained after cleaning: 9.77%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: 1-s2.0-S1350946221000367-main.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 20693\n",
      "Abstract extracted. Abstract word count: 207\n",
      "Main text word count: 20374\n",
      "After reassemble_hyphenated_words: 20254 words\n",
      "After remove_figures_tables: 20254 words\n",
      "After remove_citations: 19620 words\n",
      "After remove_urls: 18955 words\n",
      "After remove_emails: 18951 words\n",
      "After remove_numerical_references: 18951 words\n",
      "After remove_headers: 18951 words\n",
      "After remove_metadata: 18951 words\n",
      "After remove_institution_names: 18951 words\n",
      "After remove_copyright_info: 18951 words\n",
      "After remove_doi_and_journal_info: 18951 words\n",
      "After remove_artifacts: 18951 words\n",
      "After removing extra whitespace: 18951 words\n",
      "After handle_special_characters: 18932 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3:  90%|█████████ | 9/10 [00:11<00:01,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 18932 words\n",
      "Final preprocessed word count: 18932\n",
      "Percentage of words retained after cleaning: 91.49%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: fphar-12-654445.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 6259\n",
      "Abstract extracted. Abstract word count: 210\n",
      "Main text word count: 6049\n",
      "After reassemble_hyphenated_words: 6037 words\n",
      "After remove_figures_tables: 6037 words\n",
      "After remove_citations: 5751 words\n",
      "After remove_urls: 5727 words\n",
      "After remove_emails: 5721 words\n",
      "After remove_numerical_references: 5721 words\n",
      "After remove_headers: 5721 words\n",
      "After remove_metadata: 5717 words\n",
      "After remove_institution_names: 5717 words\n",
      "After remove_copyright_info: 5695 words\n",
      "After remove_doi_and_journal_info: 5695 words\n",
      "After remove_artifacts: 5695 words\n",
      "After removing extra whitespace: 5695 words\n",
      "After handle_special_characters: 5687 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3: 100%|██████████| 10/10 [00:12<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 5687 words\n",
      "Final preprocessed word count: 5687\n",
      "Percentage of words retained after cleaning: 90.86%\n",
      "====================================================================================================\n",
      "Completed processing batch 3\n",
      "\n",
      "Processing batch 4 of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: nihpp-rs3011096v1-compressed.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 14360\n",
      "Abstract extracted. Abstract word count: 252\n",
      "Main text word count: 1516\n",
      "After reassemble_hyphenated_words: 1514 words\n",
      "After remove_figures_tables: 1514 words\n",
      "After remove_citations: 1514 words\n",
      "After remove_urls: 1514 words\n",
      "After remove_emails: 1514 words\n",
      "After remove_numerical_references: 1514 words\n",
      "After remove_headers: 1514 words\n",
      "After remove_metadata: 1514 words\n",
      "After remove_institution_names: 1514 words\n",
      "After remove_copyright_info: 1514 words\n",
      "After remove_doi_and_journal_info: 1514 words\n",
      "After remove_artifacts: 1514 words\n",
      "After removing extra whitespace: 1514 words\n",
      "After handle_special_characters: 1511 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4:  10%|█         | 1/10 [00:00<00:03,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 1511 words\n",
      "Final preprocessed word count: 1511\n",
      "Percentage of words retained after cleaning: 10.52%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: nihms-1914935.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 12092\n",
      "Abstract extracted. Abstract word count: 251\n",
      "Main text word count: 1736\n",
      "After reassemble_hyphenated_words: 1734 words\n",
      "After remove_figures_tables: 1734 words\n",
      "After remove_citations: 1699 words\n",
      "After remove_urls: 1699 words\n",
      "After remove_emails: 1699 words\n",
      "After remove_numerical_references: 1699 words\n",
      "After remove_headers: 1699 words\n",
      "After remove_metadata: 1699 words\n",
      "After remove_institution_names: 1699 words\n",
      "After remove_copyright_info: 1699 words\n",
      "After remove_doi_and_journal_info: 1699 words\n",
      "After remove_artifacts: 1699 words\n",
      "After removing extra whitespace: 1699 words\n",
      "After handle_special_characters: 1682 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4:  20%|██        | 2/10 [00:00<00:03,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 1682 words\n",
      "Final preprocessed word count: 1682\n",
      "Percentage of words retained after cleaning: 13.91%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: genes-14-00074.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 10641\n",
      "Abstract extracted. Abstract word count: 173\n",
      "Main text word count: 10281\n",
      "After reassemble_hyphenated_words: 10239 words\n",
      "After remove_figures_tables: 10239 words\n",
      "After remove_citations: 10089 words\n",
      "After remove_urls: 10038 words\n",
      "After remove_emails: 10038 words\n",
      "After remove_numerical_references: 10038 words\n",
      "After remove_headers: 10038 words\n",
      "After remove_metadata: 10038 words\n",
      "After remove_institution_names: 10038 words\n",
      "After remove_copyright_info: 10038 words\n",
      "After remove_doi_and_journal_info: 10038 words\n",
      "After remove_artifacts: 10038 words\n",
      "After removing extra whitespace: 10038 words\n",
      "After handle_special_characters: 10012 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4:  30%|███       | 3/10 [00:05<00:17,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 10012 words\n",
      "Final preprocessed word count: 10012\n",
      "Percentage of words retained after cleaning: 94.09%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: 1-s2.0-S1350946220300707-main-compressed.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 34597\n",
      "Abstract extracted. Abstract word count: 249\n",
      "Main text word count: 34176\n",
      "After reassemble_hyphenated_words: 34130 words\n",
      "After remove_figures_tables: 34127 words\n",
      "After remove_citations: 32814 words\n",
      "After remove_urls: 32800 words\n",
      "After remove_emails: 32795 words\n",
      "After remove_numerical_references: 32795 words\n",
      "After remove_headers: 32795 words\n",
      "After remove_metadata: 32795 words\n",
      "After remove_institution_names: 32795 words\n",
      "After remove_copyright_info: 32795 words\n",
      "After remove_doi_and_journal_info: 32795 words\n",
      "After remove_artifacts: 32795 words\n",
      "After removing extra whitespace: 32795 words\n",
      "After handle_special_characters: 32745 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4:  40%|████      | 4/10 [00:14<00:29,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 32745 words\n",
      "Final preprocessed word count: 32745\n",
      "Percentage of words retained after cleaning: 94.65%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: Acta Ophthalmologica - 2019 - Holtan - Inherited retinal disease in Norway   a characterization of current clinical and.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 7041\n",
      "Abstract extracted. Abstract word count: 226\n",
      "Main text word count: 6707\n",
      "After reassemble_hyphenated_words: 6600 words\n",
      "After remove_figures_tables: 6599 words\n",
      "After remove_citations: 6426 words\n",
      "After remove_urls: 6318 words\n",
      "After remove_emails: 6312 words\n",
      "After remove_numerical_references: 6312 words\n",
      "After remove_headers: 6312 words\n",
      "After remove_metadata: 6312 words\n",
      "After remove_institution_names: 6312 words\n",
      "After remove_copyright_info: 6312 words\n",
      "After remove_doi_and_journal_info: 6312 words\n",
      "After remove_artifacts: 6312 words\n",
      "After removing extra whitespace: 6312 words\n",
      "After handle_special_characters: 6295 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4:  50%|█████     | 5/10 [00:15<00:18,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 6295 words\n",
      "Final preprocessed word count: 6295\n",
      "Percentage of words retained after cleaning: 89.40%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: ijms-22-07207.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 8901\n",
      "Abstract extracted. Abstract word count: 193\n",
      "Main text word count: 8361\n",
      "After reassemble_hyphenated_words: 8326 words\n",
      "After remove_figures_tables: 8326 words\n",
      "After remove_citations: 8168 words\n",
      "After remove_urls: 8116 words\n",
      "After remove_emails: 8116 words\n",
      "After remove_numerical_references: 8116 words\n",
      "After remove_headers: 8116 words\n",
      "After remove_metadata: 8116 words\n",
      "After remove_institution_names: 8116 words\n",
      "After remove_copyright_info: 8116 words\n",
      "After remove_doi_and_journal_info: 8116 words\n",
      "After remove_artifacts: 8116 words\n",
      "After removing extra whitespace: 8116 words\n",
      "After handle_special_characters: 8102 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4:  60%|██████    | 6/10 [00:17<00:11,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 8102 words\n",
      "Final preprocessed word count: 8102\n",
      "Percentage of words retained after cleaning: 91.02%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: cells-12-02579-compressed.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 14763\n",
      "Abstract extracted. Abstract word count: 224\n",
      "Main text word count: 14370\n",
      "After reassemble_hyphenated_words: 14227 words\n",
      "After remove_figures_tables: 14227 words\n",
      "After remove_citations: 14037 words\n",
      "After remove_urls: 13901 words\n",
      "After remove_emails: 13901 words\n",
      "After remove_numerical_references: 13901 words\n",
      "After remove_headers: 13901 words\n",
      "After remove_metadata: 13901 words\n",
      "After remove_institution_names: 13901 words\n",
      "After remove_copyright_info: 13901 words\n",
      "After remove_doi_and_journal_info: 13901 words\n",
      "After remove_artifacts: 13901 words\n",
      "After removing extra whitespace: 13901 words\n",
      "After handle_special_characters: 13860 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4:  70%|███████   | 7/10 [00:20<00:08,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 13860 words\n",
      "Final preprocessed word count: 13860\n",
      "Percentage of words retained after cleaning: 93.88%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: nihms-1567493.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 5167\n",
      "Abstract extracted. Abstract word count: 139\n",
      "Main text word count: 4958\n",
      "After reassemble_hyphenated_words: 4952 words\n",
      "After remove_figures_tables: 4952 words\n",
      "After remove_citations: 4673 words\n",
      "After remove_urls: 4673 words\n",
      "After remove_emails: 4669 words\n",
      "After remove_numerical_references: 4669 words\n",
      "After remove_headers: 4669 words\n",
      "After remove_metadata: 4669 words\n",
      "After remove_institution_names: 4669 words\n",
      "After remove_copyright_info: 4669 words\n",
      "After remove_doi_and_journal_info: 4669 words\n",
      "After remove_artifacts: 4669 words\n",
      "After removing extra whitespace: 4669 words\n",
      "After handle_special_characters: 4656 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4:  80%|████████  | 8/10 [00:21<00:04,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 4656 words\n",
      "Final preprocessed word count: 4656\n",
      "Percentage of words retained after cleaning: 90.11%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: NRR-18-701.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 9592\n",
      "Abstract extracted. Abstract word count: 238\n",
      "Main text word count: 2979\n",
      "After reassemble_hyphenated_words: 2973 words\n",
      "After remove_figures_tables: 2973 words\n",
      "After remove_citations: 2971 words\n",
      "After remove_urls: 2965 words\n",
      "After remove_emails: 2965 words\n",
      "After remove_numerical_references: 2965 words\n",
      "After remove_headers: 2965 words\n",
      "After remove_metadata: 2965 words\n",
      "After remove_institution_names: 2965 words\n",
      "After remove_copyright_info: 2965 words\n",
      "After remove_doi_and_journal_info: 2965 words\n",
      "After remove_artifacts: 2965 words\n",
      "After removing extra whitespace: 2965 words\n",
      "After handle_special_characters: 2961 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4:  90%|█████████ | 9/10 [00:21<00:01,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 2961 words\n",
      "Final preprocessed word count: 2961\n",
      "Percentage of words retained after cleaning: 30.87%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: 13023_2023_Article_2798.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 8984\n",
      "Abstract extracted. Abstract word count: 249\n",
      "Main text word count: 8349\n",
      "After reassemble_hyphenated_words: 8321 words\n",
      "After remove_figures_tables: 8319 words\n",
      "After remove_citations: 7897 words\n",
      "After remove_urls: 7889 words\n",
      "After remove_emails: 7889 words\n",
      "After remove_numerical_references: 7889 words\n",
      "After remove_headers: 7818 words\n",
      "After remove_metadata: 7814 words\n",
      "After remove_institution_names: 7814 words\n",
      "After remove_copyright_info: 7814 words\n",
      "After remove_doi_and_journal_info: 7814 words\n",
      "After remove_artifacts: 7814 words\n",
      "After removing extra whitespace: 7814 words\n",
      "After handle_special_characters: 7791 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4: 100%|██████████| 10/10 [00:23<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 7791 words\n",
      "Final preprocessed word count: 7791\n",
      "Percentage of words retained after cleaning: 86.72%\n",
      "====================================================================================================\n",
      "Completed processing batch 4\n",
      "\n",
      "Processing batch 5 of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: PIIS0039625723001030.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 13222\n",
      "Abstract extracted. Abstract word count: 242\n",
      "Main text word count: 5202\n",
      "After reassemble_hyphenated_words: 5189 words\n",
      "After remove_figures_tables: 5189 words\n",
      "After remove_citations: 4701 words\n",
      "After remove_urls: 4645 words\n",
      "After remove_emails: 4645 words\n",
      "After remove_numerical_references: 4645 words\n",
      "After remove_headers: 4645 words\n",
      "After remove_metadata: 4645 words\n",
      "After remove_institution_names: 4645 words\n",
      "After remove_copyright_info: 4645 words\n",
      "After remove_doi_and_journal_info: 4645 words\n",
      "After remove_artifacts: 4645 words\n",
      "After removing extra whitespace: 4645 words\n",
      "After handle_special_characters: 4633 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5:  10%|█         | 1/10 [00:01<00:09,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 4633 words\n",
      "Final preprocessed word count: 4633\n",
      "Percentage of words retained after cleaning: 35.04%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: diagnostics-13-00850.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 5979\n",
      "Abstract extracted. Abstract word count: 203\n",
      "Main text word count: 5540\n",
      "After reassemble_hyphenated_words: 5530 words\n",
      "After remove_figures_tables: 5530 words\n",
      "After remove_citations: 5446 words\n",
      "After remove_urls: 5423 words\n",
      "After remove_emails: 5423 words\n",
      "After remove_numerical_references: 5423 words\n",
      "After remove_headers: 5423 words\n",
      "After remove_metadata: 5423 words\n",
      "After remove_institution_names: 5423 words\n",
      "After remove_copyright_info: 5423 words\n",
      "After remove_doi_and_journal_info: 5423 words\n",
      "After remove_artifacts: 5423 words\n",
      "After removing extra whitespace: 5423 words\n",
      "After handle_special_characters: 5413 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5:  20%|██        | 2/10 [00:02<00:08,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 5413 words\n",
      "Final preprocessed word count: 5413\n",
      "Percentage of words retained after cleaning: 90.53%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: nihms880229.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 11916\n",
      "Abstract extracted. Abstract word count: 232\n",
      "Main text word count: 11076\n",
      "After reassemble_hyphenated_words: 11064 words\n",
      "After remove_figures_tables: 11063 words\n",
      "After remove_citations: 10618 words\n",
      "After remove_urls: 10609 words\n",
      "After remove_emails: 10609 words\n",
      "After remove_numerical_references: 10609 words\n",
      "After remove_headers: 10609 words\n",
      "After remove_metadata: 10609 words\n",
      "After remove_institution_names: 10609 words\n",
      "After remove_copyright_info: 10609 words\n",
      "After remove_doi_and_journal_info: 10609 words\n",
      "After remove_artifacts: 10609 words\n",
      "After removing extra whitespace: 10609 words\n",
      "After handle_special_characters: 10609 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5:  30%|███       | 3/10 [00:04<00:10,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 10609 words\n",
      "Final preprocessed word count: 10609\n",
      "Percentage of words retained after cleaning: 89.03%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: 41598_2021_Article_81093.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 9355\n",
      "Abstract extracted. Abstract word count: 258\n",
      "Main text word count: 4741\n",
      "After reassemble_hyphenated_words: 4736 words\n",
      "After remove_figures_tables: 4736 words\n",
      "After remove_citations: 4732 words\n",
      "After remove_urls: 4629 words\n",
      "After remove_emails: 4629 words\n",
      "After remove_numerical_references: 4629 words\n",
      "After remove_headers: 4629 words\n",
      "After remove_metadata: 4629 words\n",
      "After remove_institution_names: 4629 words\n",
      "After remove_copyright_info: 4609 words\n",
      "After remove_doi_and_journal_info: 4609 words\n",
      "After remove_artifacts: 4609 words\n",
      "After removing extra whitespace: 4609 words\n",
      "After handle_special_characters: 4541 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5:  40%|████      | 4/10 [00:05<00:07,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 4541 words\n",
      "Final preprocessed word count: 4541\n",
      "Percentage of words retained after cleaning: 48.54%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: main.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 10486\n",
      "Abstract extracted. Abstract word count: 273\n",
      "Main text word count: 10212\n",
      "After reassemble_hyphenated_words: 10088 words\n",
      "After remove_figures_tables: 10087 words\n",
      "After remove_citations: 10082 words\n",
      "After remove_urls: 10014 words\n",
      "After remove_emails: 10014 words\n",
      "After remove_numerical_references: 10014 words\n",
      "After remove_headers: 10014 words\n",
      "After remove_metadata: 10010 words\n",
      "After remove_institution_names: 10010 words\n",
      "After remove_copyright_info: 10010 words\n",
      "After remove_doi_and_journal_info: 10010 words\n",
      "After remove_artifacts: 10010 words\n",
      "After removing extra whitespace: 10010 words\n",
      "After handle_special_characters: 9993 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5:  50%|█████     | 5/10 [00:07<00:07,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 9993 words\n",
      "Final preprocessed word count: 9993\n",
      "Percentage of words retained after cleaning: 95.30%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: nihms-1933615.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 4011\n",
      "Abstract extracted. Abstract word count: 146\n",
      "Main text word count: 3796\n",
      "After reassemble_hyphenated_words: 3793 words\n",
      "After remove_figures_tables: 3793 words\n",
      "After remove_citations: 3570 words\n",
      "After remove_urls: 3552 words\n",
      "After remove_emails: 3549 words\n",
      "After remove_numerical_references: 3549 words\n",
      "After remove_headers: 3549 words\n",
      "After remove_metadata: 3549 words\n",
      "After remove_institution_names: 3549 words\n",
      "After remove_copyright_info: 3549 words\n",
      "After remove_doi_and_journal_info: 3549 words\n",
      "After remove_artifacts: 3549 words\n",
      "After removing extra whitespace: 3549 words\n",
      "After handle_special_characters: 3538 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5:  60%|██████    | 6/10 [00:08<00:05,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 3538 words\n",
      "Final preprocessed word count: 3538\n",
      "Percentage of words retained after cleaning: 88.21%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: nihms-1685213.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 10197\n",
      "Abstract extracted. Abstract word count: 212\n",
      "Main text word count: 9641\n",
      "After reassemble_hyphenated_words: 9627 words\n",
      "After remove_figures_tables: 9627 words\n",
      "After remove_citations: 8539 words\n",
      "After remove_urls: 8539 words\n",
      "After remove_emails: 8539 words\n",
      "After remove_numerical_references: 8539 words\n",
      "After remove_headers: 8539 words\n",
      "After remove_metadata: 8539 words\n",
      "After remove_institution_names: 8539 words\n",
      "After remove_copyright_info: 8539 words\n",
      "After remove_doi_and_journal_info: 8539 words\n",
      "After remove_artifacts: 8539 words\n",
      "After removing extra whitespace: 8539 words\n",
      "After handle_special_characters: 8531 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5:  70%|███████   | 7/10 [00:09<00:04,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 8531 words\n",
      "Final preprocessed word count: 8531\n",
      "Percentage of words retained after cleaning: 83.66%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: diagnostics-13-02413-compressed.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 16898\n",
      "Abstract extracted. Abstract word count: 186\n",
      "Main text word count: 16455\n",
      "After reassemble_hyphenated_words: 16376 words\n",
      "After remove_figures_tables: 16376 words\n",
      "After remove_citations: 16136 words\n",
      "After remove_urls: 16124 words\n",
      "After remove_emails: 16124 words\n",
      "After remove_numerical_references: 16124 words\n",
      "After remove_headers: 16124 words\n",
      "After remove_metadata: 16124 words\n",
      "After remove_institution_names: 16124 words\n",
      "After remove_copyright_info: 16117 words\n",
      "After remove_doi_and_journal_info: 16117 words\n",
      "After remove_artifacts: 16117 words\n",
      "After removing extra whitespace: 16117 words\n",
      "After handle_special_characters: 16064 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5:  80%|████████  | 8/10 [00:13<00:04,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 16064 words\n",
      "Final preprocessed word count: 16064\n",
      "Percentage of words retained after cleaning: 95.06%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: 41525_2021_Article_180.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 6287\n",
      "Abstract extracted. Abstract word count: 248\n",
      "Main text word count: 6025\n",
      "After reassemble_hyphenated_words: 6000 words\n",
      "After remove_figures_tables: 6000 words\n",
      "After remove_citations: 5970 words\n",
      "After remove_urls: 5890 words\n",
      "After remove_emails: 5887 words\n",
      "After remove_numerical_references: 5887 words\n",
      "After remove_headers: 5887 words\n",
      "After remove_metadata: 5887 words\n",
      "After remove_institution_names: 5887 words\n",
      "After remove_copyright_info: 5872 words\n",
      "After remove_doi_and_journal_info: 5872 words\n",
      "After remove_artifacts: 5872 words\n",
      "After removing extra whitespace: 5872 words\n",
      "After handle_special_characters: 5872 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5:  90%|█████████ | 9/10 [00:14<00:01,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 5872 words\n",
      "Final preprocessed word count: 5872\n",
      "Percentage of words retained after cleaning: 93.40%\n",
      "====================================================================================================\n",
      "\n",
      "Processing file: fgene-13-858556.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 6769\n",
      "Abstract extracted. Abstract word count: 256\n",
      "Main text word count: 5521\n",
      "After reassemble_hyphenated_words: 5518 words\n",
      "After remove_figures_tables: 5518 words\n",
      "After remove_citations: 5306 words\n",
      "After remove_urls: 5285 words\n",
      "After remove_emails: 5285 words\n",
      "After remove_numerical_references: 5285 words\n",
      "After remove_headers: 5285 words\n",
      "After remove_metadata: 5285 words\n",
      "After remove_institution_names: 5285 words\n",
      "After remove_copyright_info: 5256 words\n",
      "After remove_doi_and_journal_info: 5256 words\n",
      "After remove_artifacts: 5256 words\n",
      "After removing extra whitespace: 5256 words\n",
      "After handle_special_characters: 5255 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5: 100%|██████████| 10/10 [00:15<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 5255 words\n",
      "Final preprocessed word count: 5255\n",
      "Percentage of words retained after cleaning: 77.63%\n",
      "====================================================================================================\n",
      "Completed processing batch 5\n",
      "\n",
      "Processing batch 6 of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 6:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: biomolecules-13-00271.txt\n",
      "Starting preprocessing...\n",
      "Initial word count: 31269\n",
      "Abstract extracted. Abstract word count: 118\n",
      "Main text word count: 30950\n",
      "After reassemble_hyphenated_words: 30866 words\n",
      "After remove_figures_tables: 30866 words\n",
      "After remove_citations: 30230 words\n",
      "After remove_urls: 30212 words\n",
      "After remove_emails: 30212 words\n",
      "After remove_numerical_references: 30212 words\n",
      "After remove_headers: 30212 words\n",
      "After remove_metadata: 30212 words\n",
      "After remove_institution_names: 30212 words\n",
      "After remove_copyright_info: 30212 words\n",
      "After remove_doi_and_journal_info: 30212 words\n",
      "After remove_artifacts: 30212 words\n",
      "After removing extra whitespace: 30212 words\n",
      "After handle_special_characters: 30125 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 6: 100%|██████████| 1/1 [00:06<00:00,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detect_sentence_boundaries: 30125 words\n",
      "Final preprocessed word count: 30125\n",
      "Percentage of words retained after cleaning: 96.34%\n",
      "====================================================================================================\n",
      "Completed processing batch 6\n",
      "All batches processed.\n",
      "Preprocessing complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # input_folder = \"/mnt/data/skanda/MSc_IRD_LLM/data/txt_data\"\n",
    "    input_folder = \"/mnt/data/skanda/MSc_IRD_LLM/data/txt_data\"\n",
    "    output_folder = \"/mnt/data/skanda/MSc_IRD_LLM/data/data_preprocessed\"\n",
    "    process_files(input_folder, output_folder, batch_size=10)\n",
    "    print(\"Preprocessing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
